{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!cuda-install-samples-11.2.sh ~ && cd /root/NVIDIA_CUDA-11.2_Samples/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejUTAAyMWnge",
        "outputId": "e93f300f-cd51-4b10-b0b7-c3dd2a92764c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-g5gdzyvj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-g5gdzyvj\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=67e4f7815ee22338d51ae83a63fdbf8af079c1b598a19ba2d6d769d7697b933e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f6_d_7s3/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n",
            "/bin/bash: line 1: cuda-install-samples-11.2.sh: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name curand.cu\n",
        "#include <cstdlib>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <curand.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <time.h>\n",
        "#include <cmath>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define kernel kernel_gpu_matmul\n",
        "\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "//Умножение матриц на GPU\n",
        "__global__ void kernel_gpu_matmul(const float *A, const float *B, float *C, const int m, const int k, const int n) {\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    float temp = 0;\n",
        "    if (row < m && col < k) {\n",
        "        for (int i = 0; i < n; ++i)\n",
        "            temp += A[row * n + i] * B[i * n + col];\n",
        "        C[row * k + col] = temp;\n",
        "    }\n",
        "}\n",
        "//Умножение матриц на GPU при помощи CUBLAS\n",
        "void gpu_matmul_cublas(const float *A, const float *B, float *C, const int m, const int k, const int n) {\n",
        "    int lda=m,ldb=n,ldc=k;\n",
        "    const float alf = 1;\n",
        "    const float bet = 0;\n",
        "    const float *alpha = &alf;\n",
        "    const float *beta = &bet;\n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    // Do the actual multiplication\n",
        "    cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_T, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "}\n",
        "//Умножение матриц на CPU\n",
        "void cpu_matmul(const float* A, const float* B, float* C, const int m, const int k, const int n) {\n",
        "        for (int i = 0; i < m; ++i)\n",
        "          for (int j = 0; j < n; ++j)\n",
        "            for (int r = 0; r < k; ++r)\n",
        "                C[i * n + j] += A[i * k + r] * B[r * n + j];\n",
        "}\n",
        "//Проверка корректности перемножения\n",
        "void check_matmul(const float* C, const float* C2, const int m, const int n) {\n",
        "    for (int i = 0; i < m * n; ++i)\n",
        "        if (abs(C[i] - C2[i]) > 0.001) {\n",
        "            cout << \"The matrices are not equal\\n\";\n",
        "            return;\n",
        "        }\n",
        "    cout << \"The matrices are equal\\n\";\n",
        "}\n",
        "//Вывод матрицы\n",
        "void print_matrix(float *h_C, int nr_rows_C, int nr_cols_C) {\n",
        "    for (int i = 0; i < nr_rows_C; ++i){\n",
        "      for (int j = 0; j < nr_cols_C; ++j)\n",
        "        cout << *(h_C + i + j * nr_cols_C) << \" \";\n",
        "      cout << endl;\n",
        "    }\n",
        "}\n",
        "//Транспонирование матрицы\n",
        "void transpose(float* C, const int m, const int n) {\n",
        "    float *C2 = (float *)malloc(m * n * sizeof(float));\n",
        "    for (int i = 0; i < m; ++i)\n",
        "          for (int j = 0; j < n; ++j)\n",
        "              C2[i * n + j] = C[j * m + i];\n",
        "    for (int i = 0; i < m * n; ++i)\n",
        "        C[i] = C2[i];\n",
        "    free(C2);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int nr_rows_A, nr_cols_A, nr_rows_B, nr_cols_B, nr_rows_C, nr_cols_C;\n",
        "    nr_rows_A = nr_cols_A = nr_rows_B = nr_cols_B = nr_rows_C = nr_cols_C = 300;\n",
        "    float *h_A = (float *)malloc(nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    float *h_B = (float *)malloc(nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    float *h_C = (float *)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    float *h_C2 = (float *)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    float *h_C3 = (float *)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    float *d_A, *d_B, *d_C, *d_C3;\n",
        "\n",
        "    printf(\"Размерность матриц с типом float: %d (c T, c T)\\n\", nr_rows_A);\n",
        "    for (int i = 0; i < nr_rows_A * nr_rows_A; ++i) {\n",
        "        h_A[i] = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
        "        h_B[i] = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
        "        h_C3[i] = 0;\n",
        "    }\n",
        "    cudaMalloc(&d_A,nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    cudaMalloc(&d_B,nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    cudaMalloc(&d_C,nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    cudaMalloc(&d_C3,nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    cudaMemcpy(d_A,h_A,nr_rows_A * nr_cols_A * sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B,h_B,nr_rows_B * nr_cols_B * sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_C3,h_C3,nr_rows_B * nr_cols_B * sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "//gpu_matmul_cublas\n",
        "    srand(time(0));\n",
        "    clock_t start, end;\n",
        "    start = clock();\n",
        "    gpu_matmul_cublas(d_A, d_B, d_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    end = clock();\n",
        "    double gpu_time_cublas = static_cast <double>(end - start) / static_cast <double>(CLOCKS_PER_SEC);\n",
        "\n",
        "    cudaMemcpy(h_C,d_C,nr_rows_C * nr_cols_C * sizeof(float),cudaMemcpyDeviceToHost);\n",
        "    //Транспонирование матрицы, тк cublas возвращает результат по столбцам\n",
        "    transpose(h_C, nr_rows_C, nr_cols_C);\n",
        "    //cout << \"C =\" << endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "//cpu_matmul\n",
        "    clock_t start1, end1;\n",
        "    start1 = clock();\n",
        "    cpu_matmul(h_A, h_B, h_C2, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    end1 = clock();\n",
        "    double cpu_time = static_cast <double>(end1 - start1) / static_cast <double>(CLOCKS_PER_SEC);\n",
        "    //cout << \"C2 =\" << endl;\n",
        "    //print_matrix(h_C2, nr_rows_C, nr_cols_C);\n",
        "\n",
        "//kernel_gpu_matmul\n",
        "    cudaEvent_t begin, stop;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&stop);\n",
        "    dim3 block_dim(32, 32);\n",
        "    dim3 grid_dim(ceil(static_cast <double> (nr_rows_A) / static_cast <double> (block_dim.x)), ceil(static_cast <double> (nr_cols_A) / static_cast <double> (block_dim.y)));\n",
        "\n",
        "    cudaEventRecord(begin, 0);\n",
        "    kernel_gpu_matmul << <grid_dim, block_dim>> > (d_A, d_B, d_C3, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    cudaEventRecord(stop, 0);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    float gpu_time;\n",
        "    cudaEventElapsedTime(&gpu_time, begin, stop);\n",
        "    cudaMemcpy(h_C3,d_C3,nr_rows_C * nr_cols_C * sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        " //check_matmul\n",
        "    check_matmul(h_C, h_C2, nr_rows_C, nr_cols_C);\n",
        "    check_matmul(h_C2, h_C3, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    cout << \"CPU Time: \" << cpu_time << endl;\n",
        "    cout << \"GPU(CUBLAS) Time: \" << gpu_time_cublas << endl;\n",
        "    cout << \"GPU Time: \" << gpu_time << endl;\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_C2);\n",
        "    free(h_C3);\n",
        "    cudaFree(d_C3);\n",
        "\n",
        "    cudaEventDestroy(begin);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OXL78GIaWoOm",
        "outputId": "f6f02a19-0ca8-4266-f59f-85ba9b306916"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/curand /content/src/curand.cu -lcurand -lcublas"
      ],
      "metadata": {
        "id": "8cZgaVfDWq5F"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/curand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VcZBvN8Ws7n",
        "outputId": "5ac211fb-96b9-4133-8f14-b238b7dbdc21"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность матриц с типом float: 300 (c T, c T)\n",
            "The matrices are equal\n",
            "The matrices are equal\n",
            "CPU Time: 0.130083\n",
            "GPU(CUBLAS) Time: 0.568182\n",
            "GPU Time: 0.253312\n"
          ]
        }
      ]
    }
  ]
}