{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!cuda-install-samples-11.2.sh ~ && cd /root/NVIDIA_CUDA-11.2_Samples/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejUTAAyMWnge",
        "outputId": "6005587f-db9d-4d70-a1b4-ea0b2472d34d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-tl17143y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-tl17143y\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=796989245dabfaa40ac05192435ec6f71fd8b3cfd13ecff919db0b7ea79471a1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9q46eapv/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n",
            "/bin/bash: line 1: cuda-install-samples-11.2.sh: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name curand.cu\n",
        "#include <cstdlib>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <curand.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <time.h>\n",
        "#include <cmath>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "//Умножение матриц на GPU\n",
        "void gpu_matmul(const float *A, const float *B, float *C, const int m, const int k, const int n) {\n",
        "    int lda=m,ldb=n,ldc=k;\n",
        "    const float alf = 1;\n",
        "    const float bet = 0;\n",
        "    const float *alpha = &alf;\n",
        "    const float *beta = &bet;\n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    // Do the actual multiplication\n",
        "    cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_T, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "}\n",
        "//Умножение матриц на CPU\n",
        "void cpu_matmul(const float* A, const float* B, float* C, const int m, const int k, const int n) {\n",
        "        for (int i = 0; i < m; ++i)\n",
        "          for (int j = 0; j < n; ++j)\n",
        "            for (int r = 0; r < k; ++r)\n",
        "                C[i * n + j] += A[i * k + r] * B[r * n + j];\n",
        "}\n",
        "//Проверка корректности перемножения\n",
        "void check_matmul(const float* C, const float* C2, const int m, const int n) {\n",
        "    for (int i = 0; i < m * n; ++i)\n",
        "        if (abs(C[i] - C2[i]) > 0.001) {\n",
        "            cout << \"The matrices are not equal\\n\";\n",
        "            return;\n",
        "        }\n",
        "    cout << \"The matrices are equal\\n\";\n",
        "}\n",
        "//Вывод матрицы\n",
        "void print_matrix(float *h_C, int nr_rows_C, int nr_cols_C) {\n",
        "    for (int i = 0; i < nr_rows_C; ++i){\n",
        "      for (int j = 0; j < nr_cols_C; ++j)\n",
        "        cout << *(h_C + i + j * nr_cols_C) << \" \";\n",
        "      cout << endl;\n",
        "    }\n",
        "}\n",
        "//Транспонирование матрицы\n",
        "void transpose(float* C, const int m, const int n) {\n",
        "    float *C2 = (float *)malloc(m * n * sizeof(float));\n",
        "    for (int i = 0; i < m; ++i)\n",
        "          for (int j = 0; j < n; ++j)\n",
        "              C2[i * n + j] = C[j * m + i];\n",
        "    for (int i = 0; i < m * n; ++i)\n",
        "        C[i] = C2[i];\n",
        "    free(C2);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int nr_rows_A, nr_cols_A, nr_rows_B, nr_cols_B, nr_rows_C, nr_cols_C;\n",
        "    nr_rows_A = nr_cols_A = nr_rows_B = nr_cols_B = nr_rows_C = nr_cols_C = 2000;\n",
        "    float *h_A = (float *)malloc(nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    float *h_B = (float *)malloc(nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    float *h_C = (float *)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    float *h_C2 = (float *)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    printf(\"Размерность матриц с типом float: %d (c T, c T)\\n\", nr_rows_A);\n",
        "    for (int i = 0; i < nr_rows_A * nr_rows_A; ++i) {\n",
        "        h_A[i] = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
        "        h_B[i] = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
        "    }\n",
        "    cudaMalloc(&d_A,nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    cudaMalloc(&d_B,nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    cudaMalloc(&d_C,nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    cudaMemcpy(d_A,h_A,nr_rows_A * nr_cols_A * sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B,h_B,nr_rows_B * nr_cols_B * sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    srand(time(0));\n",
        "    clock_t start, end;\n",
        "    start = clock();\n",
        "    gpu_matmul(d_A, d_B, d_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    end = clock();\n",
        "    double gpu_time = static_cast <double>(end - start) / static_cast <double>(CLOCKS_PER_SEC);\n",
        "\n",
        "    cudaMemcpy(h_C,d_C,nr_rows_C * nr_cols_C * sizeof(float),cudaMemcpyDeviceToHost);\n",
        "    //Транспонирование матрицы, тк cublas возвращает результат по столбцам\n",
        "    transpose(h_C, nr_rows_C, nr_cols_C);\n",
        "    //cout << \"C =\" << endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    clock_t start1, end1;\n",
        "    start1 = clock();\n",
        "    cpu_matmul(h_A, h_B, h_C2, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    end1 = clock();\n",
        "    double cpu_time = static_cast <double>(end1 - start1) / static_cast <double>(CLOCKS_PER_SEC);\n",
        "    //cout << \"C2 =\" << endl;\n",
        "    //print_matrix(h_C2, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    check_matmul(h_C, h_C2, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    cout << \"CPU Time: \" << cpu_time << endl;\n",
        "    cout << \"GPU Time: \" << gpu_time << endl;\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_C2);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OXL78GIaWoOm",
        "outputId": "a03f6a60-b751-462d-ff76-b6d77a9d977f"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/curand /content/src/curand.cu -lcurand -lcublas"
      ],
      "metadata": {
        "id": "8cZgaVfDWq5F"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/curand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VcZBvN8Ws7n",
        "outputId": "d5e3ee9a-60bb-4833-8b8a-43cbca03bd36"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность матриц с типом float: 2000 (c T, c T)\n",
            "The matrices are equal\n",
            "CPU Time: 93.7883\n",
            "GPU Time: 0.58442\n"
          ]
        }
      ]
    }
  ]
}